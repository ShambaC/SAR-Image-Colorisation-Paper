Synthetic Aperture Radar (SAR) has become an indispensable tool in remote sensing, offering robust imaging capabilities indepenedent of weather conditions or daylight availability. By actively transmitting microwave signals and capturing their backscatter from Earth's surface, SAR systems produce images rich in structural information. However, these images are inherently grayscale and lack color information, limiting their intuitive interpretation and practical utility in visual analysis tasks. This lack of color has become a serious hindrance to the utilization of the SAR images.

This problem is certainly not new and has been tackled in the past using various implementations of Generative Adversarial Networks (GANs). As per a review published in 2023, a few major work on this problem have used \textbf{cGAN}, \textbf{DCGAN}, \textbf{Pix2Pix GAN} and \textbf{CycleGAN}\cite{SARReview}. It can be seen that all implementations are various different forms of GANs. Thus, in this project we address the problem of SAR image colorisation using Latent Diffusion Model (LDM). Unlike conventional generative models, LDMs operate in a compressed latent space, making them computationally efficient while retaining high fidelity in image synthesis. Also, with the help of LDMs, we can include text conditioning which further increases the configurability of the image colorisation process. Further information regarding this is explained in section \ref{sec:WhyLDM}.

To train our model, we have also prepared a large dataset of paired Sentinel 1 and Sentinel 2 images along with seasonal metadata for the locations depicted in the images. Further information regarding the dataset and its preparation is explained in chapter \ref{chap:Dataset}.

Through this work, we aim to enhance the accessibility and interpretability of SAR imagery. The results demonstrate that deep generative models can not only reconstruct plausible color representations from SAR data but also align these representations with meaningful environmental contexts.